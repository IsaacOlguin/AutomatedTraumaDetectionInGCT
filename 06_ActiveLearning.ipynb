{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3laF9JUQJ2vC/Zqty5Gav"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Active Learning"],"metadata":{"id":"_CRzA_p-JBLK"}},{"cell_type":"code","source":["#%load_ext autoreload\n","#%autoreload 2\n","\n","GLB_USE_DRIVE_ACCOUNT = True\n","GLB_INSTALL_DEPENDENCIES = True\n","\n","if GLB_USE_DRIVE_ACCOUNT:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/\"Colab Notebooks\"\n","  username = \"IsaacOlguin\"\n","  repository =  \"AutomatedTraumaDetectionInGCT\"\n","  %cd {repository}\n","  %pwd\n","\n","if GLB_INSTALL_DEPENDENCIES:\n","    !pip install transformers\n","    #!pip install torch\n","    #!pip install openpyxl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0NCLaRdAJJRa","executionInfo":{"status":"ok","timestamp":1674076707065,"user_tz":-60,"elapsed":50599,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"9344e6a5-faf0-4771-bc39-10ea95aefd2e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks\n","/content/drive/MyDrive/Colab Notebooks/AutomatedTraumaDetectionInGCT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}]},{"cell_type":"markdown","source":["## Execution of the **active learning**"],"metadata":{"id":"4wkBAv8FJ2la"}},{"cell_type":"code","source":["!python /content/drive/MyDrive/\"Colab Notebooks\"/AutomatedTraumaDetectionInGCT/src/active_learning.py"],"metadata":{"id":"nOQb5OeaOs7e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674087907670,"user_tz":-60,"elapsed":9698141,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"980f536b-394a-428b-a0bc-222da8dbec93"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:__main__:Reading directory path\n","DEBUG:__main__:{'google_drive_friendly': True, 'general_set_up': {'dataset_filename': 'Dataset.xlsx', 'input_dir_name': 'input', 'output_dir_name': 'output', 'dataset_dir_name': 'dataset', 'logs_dir_name': 'logs', 'models_dir_name': 'models'}, 'dataset': {'index_columns_dataset': 0, 'list_columns_names': ['id_document', 'id_annotation', 'span', 'role', 'trauma', 'court'], 'col_of_interest_binary_classif': 'trauma', 'col_of_interest_multi_label_classif': 'role', 'col_of_reference_binary_classif': 'span', 'col_of_reference_multi_label_classif': 'span'}, 'training_model': {'epochs': 3, 'batch_size': 8, 'embedding_size': 512, 'return_attention_mask': True, 'cross_validation': False, 'save_model': False, 'store_statistics': False, 'test_model': False, 'add_special_tokes': True, 'max_length': 512, 'pad_to_max_length': True, 'run_in_gpu': True, 'classification_task': 'binary'}, 'active_training': {'size_splits_dataset': 5, 'classification_task': 'multi'}}\n","DEBUG:__main__:Num of different roles in the dataset is 7 which are:\n","DEBUG:__main__:\t 1 - Witness\n","DEBUG:__main__:\t 2 - LawyerQA\n","DEBUG:__main__:\t 3 - JudgeProc\n","DEBUG:__main__:\t 4 - LawyerProc\n","DEBUG:__main__:\t 5 - JudgeQA\n","DEBUG:__main__:\t 6 - Court Proceedings\n","DEBUG:__main__:\t 7 - Accused\n","INFO:__main__:There are 1 GPU(s) available.\n","\n","These are the available devices:\n","INFO:__main__:\t 1 - Tesla T4\n","DEBUG:__main__:\n","\n","==> Selected device is 'cuda' <==\n","DEBUG:__main__:Loading BERT tokenizer...\n","INFO:__main__:Bert tokenizer was loaded successfully (bert-base-uncased)\n","\tdo_lower_case=True\n","INFO:__main__:Max sentence length: 323 found at index 2524. Sentence is:\n","\n","\n","As for -- I tried to raise three children from their mother, but I could not do that, but they were not from Amleang. As for the flood, I would like to tell you the truth as the following.  A flood from the mountainous area, I had explained to the Chambers earlier that that day there was a slight rain at the place about 9:00 a.m. in the morning.  It was not a heavy rain that day, but there was flood that's about one metre in height in one hour.  It's very quick.  I saw that.  Then I stand -- I stood next to the pits and I told them, \"Come out, come out\" including myself and others would catch the bin and water above my chest. Everybody was in the same situation. In the evening, about 3:00 p.m., then the water level went down. At that time, I rescued the prisoner and the guards to Chot's house.  It's the village chief of the Trapeang Traob village. And therefore there was no prisoner died in the flood there.  As I told Your Honours earlier, no one died in the flood.  No one climbed up into the tree.  And there was a small hill next to Chot's house.  Chot was the chief of the village and at that time we cross... we could not cross to the house of Brother Chot because there was a pond there.  And before the person did not see anything and come to testify at the court, we cannot say it is correct.\n","\n","\n","\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","INFO:__main__:\n","CORPUS TRAINING AND VALIDATION: \n","            \n","\t Length labels 2426\n","            \n","\t Length input_ids 2426\n","            \n","\t Length attention_masks 2426\n","            \n","\n","INFO:__main__:\n","\tCORPUS TRAINING:  \n","            \n","\t\t Length labels 2183\n","            \n","\t\t Length input_ids 2183\n","            \n","\t\t Length attention_masks 2183\n","INFO:__main__:\n","\tCORPUS VALIDATION: \n","            \n","\t\t Length labels 243\n","            \n","\t\t Length input_ids 243\n","            \n","\t\t Length attention_masks 243\n","INFO:__main__:\n","INFO:__main__:\n","CORPUS TEST: \n","            \n","\t Length labels 128\n","            \n","\t Length input_ids 128\n","            \n","\t Length attention_masks 128\n","            \n","\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 1 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    273.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of    273.    Elapsed: 0:02:28.\n","INFO:__main__:Epoch 1 : \n","            Train_acc : 0.6529492691980211\n","            Train_precision (macro, micro): [0.48034528 0.65294927]\n","            Train_recall  (macro, micro): [0.40810856 0.65294927]\n","            Train_F1 : [0.40738513 0.65294927]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.64\n","INFO:__main__:  Training epoch took: 0:03:23\n","INFO:__main__:Classification report. TRAINING at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.91      0.92      0.91       815\n","           1       0.77      0.93      0.84       673\n","           2       0.80      0.82      0.81       246\n","           3       0.74      0.79      0.76       209\n","           4       0.07      0.01      0.02       108\n","           5       0.94      0.44      0.60        78\n","           6       0.83      0.28      0.42        54\n","\n","    accuracy                           0.82      2183\n","   macro avg       0.72      0.60      0.62      2183\n","weighted avg       0.79      0.82      0.80      2183\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 1 : \n","                Valid_acc : 0.9244763434370102\n","                Valid_precision (macro, micro): [0.76732704 0.92447634]\n","                Valid_recall (macro, micro): [0.78663989 0.92447634]\n","                Valid_F1 (macro, micro): [0.7693962  0.92447634]\n","INFO:__main__:  Accuracy: 0.92\n","INFO:__main__:  Validation Loss: 0.29\n","INFO:__main__:  Validation took: 0:00:08\n","INFO:__main__:Classification report. VALIDATION at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99        91\n","           1       0.86      0.97      0.91        75\n","           2       0.93      1.00      0.96        27\n","           3       0.92      0.96      0.94        23\n","           4       0.00      0.00      0.00        12\n","           5       1.00      1.00      1.00         9\n","           6       1.00      0.67      0.80         6\n","\n","    accuracy                           0.93       243\n","   macro avg       0.81      0.80      0.80       243\n","weighted avg       0.89      0.93      0.91       243\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 2 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    273.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    273.    Elapsed: 0:02:29.\n","INFO:__main__:Epoch 2 : \n","            Train_acc : 0.9351858049194429\n","            Train_precision (macro, micro): [0.81937411 0.9351858 ]\n","            Train_recall  (macro, micro): [0.81035802 0.9351858 ]\n","            Train_F1 : [0.81134213 0.9351858 ]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.23\n","INFO:__main__:  Training epoch took: 0:03:23\n","INFO:__main__:Classification report. TRAINING at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       815\n","           1       0.87      0.98      0.92       673\n","           2       0.93      0.99      0.96       246\n","           3       0.93      0.99      0.96       209\n","           4       0.00      0.00      0.00       108\n","           5       0.97      0.97      0.97        78\n","           6       1.00      0.78      0.88        54\n","\n","    accuracy                           0.94      2183\n","   macro avg       0.81      0.82      0.81      2183\n","weighted avg       0.89      0.94      0.91      2183\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 2 : \n","                Valid_acc : 0.935470410114026\n","                Valid_precision (macro, micro): [0.95071927 0.93547041]\n","                Valid_recall (macro, micro): [0.83537294 0.93547041]\n","                Valid_F1 (macro, micro): [0.85049309 0.93547041]\n","INFO:__main__:  Accuracy: 0.94\n","INFO:__main__:  Validation Loss: 0.26\n","INFO:__main__:  Validation took: 0:00:08\n","INFO:__main__:Classification report. VALIDATION at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99        91\n","           1       0.87      0.99      0.93        75\n","           2       0.93      1.00      0.96        27\n","           3       0.96      0.96      0.96        23\n","           4       1.00      0.08      0.15        12\n","           5       1.00      1.00      1.00         9\n","           6       1.00      0.67      0.80         6\n","\n","    accuracy                           0.94       243\n","   macro avg       0.96      0.81      0.83       243\n","weighted avg       0.94      0.94      0.92       243\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 3 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    273.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of    273.    Elapsed: 0:02:29.\n","INFO:__main__:Epoch 3 : \n","            Train_acc : 0.9542518393197146\n","            Train_precision (macro, micro): [0.95872205 0.95425184]\n","            Train_recall  (macro, micro): [0.86155036 0.95425184]\n","            Train_F1 : [0.87579559 0.95425184]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.17\n","INFO:__main__:  Training epoch took: 0:03:23\n","INFO:__main__:Classification report. TRAINING at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       815\n","           1       0.90      0.98      0.94       673\n","           2       0.94      1.00      0.97       246\n","           3       0.96      0.99      0.97       209\n","           4       0.86      0.29      0.43       108\n","           5       1.00      0.97      0.99        78\n","           6       1.00      0.89      0.94        54\n","\n","    accuracy                           0.95      2183\n","   macro avg       0.95      0.87      0.89      2183\n","weighted avg       0.95      0.95      0.94      2183\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 3 : \n","                Valid_acc : 0.9120011984089742\n","                Valid_precision (macro, micro): [0.83117555 0.9120012 ]\n","                Valid_recall (macro, micro): [0.78097314 0.9120012 ]\n","                Valid_F1 (macro, micro): [0.78922463 0.9120012 ]\n","INFO:__main__:  Accuracy: 0.94\n","INFO:__main__:  Validation Loss: 0.22\n","INFO:__main__:  Validation took: 0:00:08\n","INFO:__main__:Classification report. VALIDATION at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99        91\n","           1       0.88      0.97      0.92        75\n","           2       0.96      1.00      0.98        27\n","           3       0.96      0.96      0.96        23\n","           4       0.75      0.25      0.38        12\n","           5       1.00      1.00      1.00         9\n","           6       1.00      0.67      0.80         6\n","\n","    accuracy                           0.94       243\n","   macro avg       0.93      0.84      0.86       243\n","weighted avg       0.94      0.94      0.93       243\n","\n","DEBUG:__main__:\n","INFO:__main__:Training complete!\n","INFO:__main__:Total training took 0:10:34 (h:mm:ss)\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:********************************************************************************\n","INFO:__main__:[{'epoch': 1, 'Training Loss': 0.6419800456968092, 'Training Accur.': 0.6529492691980211, 'Training Precision (macro)': 0.4803452778640298, 'Training Precision (micro)': 0.6529492691980211, 'Training Recall (macro)': 0.40810856254330047, 'Training Recall (micro)': 0.6529492691980211, 'Training F1 (macro)': 0.40738512984308467, 'Training F1 (micro)': 0.6529492691980211, 'Valid. Loss': 0.293844816365069, 'Valid. Accur.': 0.924731182795699, 'Valid. Precision (macro)': 0.7673270433707888, 'Valid. Precision (micro)': 0.9244763434370102, 'Valid. Recall (macro)': 0.7866398922055351, 'Valid. Recall (micro)': 0.9244763434370102, 'Valid. F1 (macro)': 0.7693962022437939, 'Valid. F1 (micro)': 0.9244763434370102, 'Training Time': '0:03:23', 'Validation Time': '0:00:08'}, {'epoch': 2, 'Training Loss': 0.23150285094764916, 'Training Accur.': 0.9351858049194429, 'Training Precision (macro)': 0.8193741144621107, 'Training Precision (micro)': 0.9351858049194429, 'Training Recall (macro)': 0.8103580202632313, 'Training Recall (micro)': 0.9351858049194429, 'Training F1 (macro)': 0.8113421314473519, 'Training F1 (micro)': 0.9351858049194429, 'Valid. Loss': 0.2587809184145543, 'Valid. Accur.': 0.9395161290322581, 'Valid. Precision (macro)': 0.9507192695990788, 'Valid. Precision (micro)': 0.935470410114026, 'Valid. Recall (macro)': 0.8353729350566251, 'Valid. Recall (micro)': 0.935470410114026, 'Valid. F1 (macro)': 0.8504930855621397, 'Valid. F1 (micro)': 0.935470410114026, 'Training Time': '0:03:23', 'Validation Time': '0:00:08'}, {'epoch': 3, 'Training Loss': 0.171843128609761, 'Training Accur.': 0.9542518393197146, 'Training Precision (macro)': 0.9587220526447716, 'Training Precision (micro)': 0.9542518393197146, 'Training Recall (macro)': 0.8615503582661395, 'Training Recall (micro)': 0.9542518393197146, 'Training F1 (macro)': 0.8757955868537757, 'Training F1 (micro)': 0.9542518393197146, 'Valid. Loss': 0.22396792244586733, 'Valid. Accur.': 0.9435483870967742, 'Valid. Precision (macro)': 0.8311755454932185, 'Valid. Precision (micro)': 0.9120011984089742, 'Valid. Recall (macro)': 0.7809731433489672, 'Valid. Recall (micro)': 0.9120011984089742, 'Valid. F1 (macro)': 0.7892246252025439, 'Valid. F1 (micro)': 0.9120011984089742, 'Training Time': '0:03:23', 'Validation Time': '0:00:08'}]\n","DEBUG:__main__:********************************************************************************\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:Num of different roles in the dataset is 7 which are:\n","DEBUG:__main__:\t 1 - Witness\n","DEBUG:__main__:\t 2 - LawyerQA\n","DEBUG:__main__:\t 3 - JudgeProc\n","DEBUG:__main__:\t 4 - LawyerProc\n","DEBUG:__main__:\t 5 - JudgeQA\n","DEBUG:__main__:\t 6 - Court Proceedings\n","DEBUG:__main__:\t 7 - Accused\n","INFO:__main__:There are 1 GPU(s) available.\n","\n","These are the available devices:\n","INFO:__main__:\t 1 - Tesla T4\n","DEBUG:__main__:\n","\n","==> Selected device is 'cuda' <==\n","DEBUG:__main__:Loading BERT tokenizer...\n","INFO:__main__:Bert tokenizer was loaded successfully (bert-base-uncased)\n","\tdo_lower_case=True\n","INFO:__main__:Max sentence length: 323 found at index 2524. Sentence is:\n","\n","\n","As for -- I tried to raise three children from their mother, but I could not do that, but they were not from Amleang. As for the flood, I would like to tell you the truth as the following.  A flood from the mountainous area, I had explained to the Chambers earlier that that day there was a slight rain at the place about 9:00 a.m. in the morning.  It was not a heavy rain that day, but there was flood that's about one metre in height in one hour.  It's very quick.  I saw that.  Then I stand -- I stood next to the pits and I told them, \"Come out, come out\" including myself and others would catch the bin and water above my chest. Everybody was in the same situation. In the evening, about 3:00 p.m., then the water level went down. At that time, I rescued the prisoner and the guards to Chot's house.  It's the village chief of the Trapeang Traob village. And therefore there was no prisoner died in the flood there.  As I told Your Honours earlier, no one died in the flood.  No one climbed up into the tree.  And there was a small hill next to Chot's house.  Chot was the chief of the village and at that time we cross... we could not cross to the house of Brother Chot because there was a pond there.  And before the person did not see anything and come to testify at the court, we cannot say it is correct.\n","\n","\n","\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","INFO:__main__:\n","CORPUS TRAINING AND VALIDATION: \n","            \n","\t Length labels 4852\n","            \n","\t Length input_ids 4852\n","            \n","\t Length attention_masks 4852\n","            \n","\n","INFO:__main__:\n","\tCORPUS TRAINING:  \n","            \n","\t\t Length labels 4366\n","            \n","\t\t Length input_ids 4366\n","            \n","\t\t Length attention_masks 4366\n","INFO:__main__:\n","\tCORPUS VALIDATION: \n","            \n","\t\t Length labels 486\n","            \n","\t\t Length input_ids 486\n","            \n","\t\t Length attention_masks 486\n","INFO:__main__:\n","INFO:__main__:\n","CORPUS TEST: \n","            \n","\t Length labels 256\n","            \n","\t Length input_ids 256\n","            \n","\t Length attention_masks 256\n","            \n","\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 1 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    546.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    546.    Elapsed: 0:02:30.\n","DEBUG:__main__:  Batch   300  of    546.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    546.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of    546.    Elapsed: 0:06:13.\n","INFO:__main__:Epoch 1 : \n","            Train_acc : 0.765749263785497\n","            Train_precision (macro, micro): [0.52550444 0.76574926]\n","            Train_recall  (macro, micro): [0.48306915 0.76574926]\n","            Train_F1 : [0.4721171  0.76574926]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.54\n","INFO:__main__:  Training epoch took: 0:06:48\n","INFO:__main__:Classification report. TRAINING at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.95      0.97      0.96      1631\n","           1       0.84      0.95      0.89      1347\n","           2       0.71      0.93      0.80       490\n","           3       0.80      0.74      0.77       418\n","           4       0.05      0.01      0.02       215\n","           5       0.92      0.59      0.72       157\n","           6       0.78      0.06      0.12       108\n","\n","    accuracy                           0.85      4366\n","   macro avg       0.72      0.61      0.61      4366\n","weighted avg       0.82      0.85      0.83      4366\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 1 : \n","                Valid_acc : 0.9097262715547887\n","                Valid_precision (macro, micro): [0.76652901 0.90972627]\n","                Valid_recall (macro, micro): [0.70852981 0.90972627]\n","                Valid_F1 (macro, micro): [0.7073576  0.90972627]\n","INFO:__main__:  Accuracy: 0.92\n","INFO:__main__:  Validation Loss: 0.29\n","INFO:__main__:  Validation took: 0:00:16\n","INFO:__main__:Classification report. VALIDATION at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       181\n","           1       0.83      0.99      0.90       150\n","           2       0.96      1.00      0.98        55\n","           3       0.92      0.96      0.94        46\n","           4       0.00      0.00      0.00        24\n","           5       0.94      0.89      0.91        18\n","           6       1.00      0.25      0.40        12\n","\n","    accuracy                           0.92       486\n","   macro avg       0.81      0.73      0.73       486\n","weighted avg       0.88      0.92      0.89       486\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 2 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    546.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of    546.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of    546.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    546.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of    546.    Elapsed: 0:06:13.\n","INFO:__main__:Epoch 2 : \n","            Train_acc : 0.9272220042058863\n","            Train_precision (macro, micro): [0.90067943 0.927222  ]\n","            Train_recall  (macro, micro): [0.76239878 0.927222  ]\n","            Train_F1 : [0.77382047 0.927222  ]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.26\n","INFO:__main__:  Training epoch took: 0:06:47\n","INFO:__main__:Classification report. TRAINING at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00      1631\n","           1       0.86      0.97      0.91      1347\n","           2       0.92      0.97      0.95       490\n","           3       0.91      0.97      0.94       418\n","           4       0.67      0.16      0.26       215\n","           5       0.96      0.92      0.94       157\n","           6       0.94      0.44      0.59       108\n","\n","    accuracy                           0.93      4366\n","   macro avg       0.89      0.77      0.80      4366\n","weighted avg       0.92      0.93      0.91      4366\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 2 : \n","                Valid_acc : 0.9354817044279922\n","                Valid_precision (macro, micro): [0.84287379 0.9354817 ]\n","                Valid_recall (macro, micro): [0.83698691 0.9354817 ]\n","                Valid_F1 (macro, micro): [0.83716451 0.9354817 ]\n","INFO:__main__:  Accuracy: 0.92\n","INFO:__main__:  Validation Loss: 0.25\n","INFO:__main__:  Validation took: 0:00:17\n","INFO:__main__:Classification report. VALIDATION at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       181\n","           1       0.93      0.91      0.92       150\n","           2       0.93      1.00      0.96        55\n","           3       0.89      0.91      0.90        46\n","           4       0.62      0.67      0.64        24\n","           5       0.94      0.83      0.88        18\n","           6       0.60      0.50      0.55        12\n","\n","    accuracy                           0.92       486\n","   macro avg       0.84      0.83      0.83       486\n","weighted avg       0.92      0.92      0.92       486\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 3 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    546.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    546.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of    546.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    546.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of    546.    Elapsed: 0:06:13.\n","INFO:__main__:Epoch 3 : \n","            Train_acc : 0.9567057358620757\n","            Train_precision (macro, micro): [0.93229882 0.95670574]\n","            Train_recall  (macro, micro): [0.87834987 0.95670574]\n","            Train_F1 : [0.89882168 0.95670574]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.15\n","INFO:__main__:  Training epoch took: 0:06:47\n","INFO:__main__:Classification report. TRAINING at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1631\n","           1       0.93      0.96      0.95      1347\n","           2       0.95      0.99      0.97       490\n","           3       0.94      0.98      0.96       418\n","           4       0.80      0.60      0.68       215\n","           5       0.97      0.95      0.96       157\n","           6       0.96      0.75      0.84       108\n","\n","    accuracy                           0.96      4366\n","   macro avg       0.94      0.89      0.91      4366\n","weighted avg       0.96      0.96      0.95      4366\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 3 : \n","                Valid_acc : 0.9584350341929634\n","                Valid_precision (macro, micro): [0.91923254 0.95843503]\n","                Valid_recall (macro, micro): [0.90708774 0.95843503]\n","                Valid_F1 (macro, micro): [0.90772264 0.95843503]\n","INFO:__main__:  Accuracy: 0.96\n","INFO:__main__:  Validation Loss: 0.18\n","INFO:__main__:  Validation took: 0:00:16\n","INFO:__main__:Classification report. VALIDATION at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       181\n","           1       0.93      0.99      0.96       150\n","           2       0.98      1.00      0.99        55\n","           3       0.96      0.96      0.96        46\n","           4       0.84      0.67      0.74        24\n","           5       1.00      0.89      0.94        18\n","           6       0.82      0.75      0.78        12\n","\n","    accuracy                           0.96       486\n","   macro avg       0.93      0.89      0.91       486\n","weighted avg       0.96      0.96      0.96       486\n","\n","DEBUG:__main__:\n","INFO:__main__:Training complete!\n","INFO:__main__:Total training took 0:21:12 (h:mm:ss)\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:********************************************************************************\n","INFO:__main__:[{'epoch': 1, 'Training Loss': 0.5421109391929029, 'Training Accur.': 0.765749263785497, 'Training Precision (macro)': 0.5255044351505015, 'Training Precision (micro)': 0.765749263785497, 'Training Recall (macro)': 0.48306915332487277, 'Training Recall (micro)': 0.765749263785497, 'Training F1 (macro)': 0.4721171026716908, 'Training F1 (micro)': 0.765749263785497, 'Valid. Loss': 0.2935747887756004, 'Valid. Accur.': 0.9180327868852459, 'Valid. Precision (macro)': 0.7665290088426432, 'Valid. Precision (micro)': 0.9097262715547887, 'Valid. Recall (macro)': 0.7085298059101803, 'Valid. Recall (micro)': 0.9097262715547887, 'Valid. F1 (macro)': 0.707357602677676, 'Valid. F1 (micro)': 0.9097262715547887, 'Training Time': '0:06:48', 'Validation Time': '0:00:16'}, {'epoch': 2, 'Training Loss': 0.25715646729037, 'Training Accur.': 0.9272220042058863, 'Training Precision (macro)': 0.9006794260603073, 'Training Precision (micro)': 0.9272220042058863, 'Training Recall (macro)': 0.7623987767817565, 'Training Recall (micro)': 0.9272220042058863, 'Training F1 (macro)': 0.7738204716316212, 'Training F1 (micro)': 0.9272220042058863, 'Valid. Loss': 0.2526587450105819, 'Valid. Accur.': 0.9241803278688525, 'Valid. Precision (macro)': 0.8428737910659012, 'Valid. Precision (micro)': 0.9354817044279922, 'Valid. Recall (macro)': 0.8369869124853286, 'Valid. Recall (micro)': 0.9354817044279922, 'Valid. F1 (macro)': 0.8371645073247556, 'Valid. F1 (micro)': 0.9354817044279922, 'Training Time': '0:06:47', 'Validation Time': '0:00:17'}, {'epoch': 3, 'Training Loss': 0.15065730004279274, 'Training Accur.': 0.9567057358620757, 'Training Precision (macro)': 0.9322988221438004, 'Training Precision (micro)': 0.9567057358620757, 'Training Recall (macro)': 0.8783498740673982, 'Training Recall (micro)': 0.9567057358620757, 'Training F1 (macro)': 0.8988216816599333, 'Training F1 (micro)': 0.9567057358620757, 'Valid. Loss': 0.18044597319075378, 'Valid. Accur.': 0.9610655737704918, 'Valid. Precision (macro)': 0.9192325399415963, 'Valid. Precision (micro)': 0.9584350341929634, 'Valid. Recall (macro)': 0.907087740061095, 'Valid. Recall (micro)': 0.9584350341929634, 'Valid. F1 (macro)': 0.9077226430000105, 'Valid. F1 (micro)': 0.9584350341929634, 'Training Time': '0:06:47', 'Validation Time': '0:00:16'}]\n","DEBUG:__main__:********************************************************************************\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:Num of different roles in the dataset is 7 which are:\n","DEBUG:__main__:\t 1 - Witness\n","DEBUG:__main__:\t 2 - LawyerQA\n","DEBUG:__main__:\t 3 - JudgeProc\n","DEBUG:__main__:\t 4 - LawyerProc\n","DEBUG:__main__:\t 5 - JudgeQA\n","DEBUG:__main__:\t 6 - Court Proceedings\n","DEBUG:__main__:\t 7 - Accused\n","INFO:__main__:There are 1 GPU(s) available.\n","\n","These are the available devices:\n","INFO:__main__:\t 1 - Tesla T4\n","DEBUG:__main__:\n","\n","==> Selected device is 'cuda' <==\n","DEBUG:__main__:Loading BERT tokenizer...\n","INFO:__main__:Bert tokenizer was loaded successfully (bert-base-uncased)\n","\tdo_lower_case=True\n","INFO:__main__:Max sentence length: 323 found at index 2524. Sentence is:\n","\n","\n","As for -- I tried to raise three children from their mother, but I could not do that, but they were not from Amleang. As for the flood, I would like to tell you the truth as the following.  A flood from the mountainous area, I had explained to the Chambers earlier that that day there was a slight rain at the place about 9:00 a.m. in the morning.  It was not a heavy rain that day, but there was flood that's about one metre in height in one hour.  It's very quick.  I saw that.  Then I stand -- I stood next to the pits and I told them, \"Come out, come out\" including myself and others would catch the bin and water above my chest. Everybody was in the same situation. In the evening, about 3:00 p.m., then the water level went down. At that time, I rescued the prisoner and the guards to Chot's house.  It's the village chief of the Trapeang Traob village. And therefore there was no prisoner died in the flood there.  As I told Your Honours earlier, no one died in the flood.  No one climbed up into the tree.  And there was a small hill next to Chot's house.  Chot was the chief of the village and at that time we cross... we could not cross to the house of Brother Chot because there was a pond there.  And before the person did not see anything and come to testify at the court, we cannot say it is correct.\n","\n","\n","\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","INFO:__main__:\n","CORPUS TRAINING AND VALIDATION: \n","            \n","\t Length labels 7278\n","            \n","\t Length input_ids 7278\n","            \n","\t Length attention_masks 7278\n","            \n","\n","INFO:__main__:\n","\tCORPUS TRAINING:  \n","            \n","\t\t Length labels 6550\n","            \n","\t\t Length input_ids 6550\n","            \n","\t\t Length attention_masks 6550\n","INFO:__main__:\n","\tCORPUS VALIDATION: \n","            \n","\t\t Length labels 728\n","            \n","\t\t Length input_ids 728\n","            \n","\t\t Length attention_masks 728\n","INFO:__main__:\n","INFO:__main__:\n","CORPUS TEST: \n","            \n","\t Length labels 384\n","            \n","\t Length input_ids 384\n","            \n","\t Length attention_masks 384\n","            \n","\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 1 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    819.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    819.    Elapsed: 0:02:30.\n","DEBUG:__main__:  Batch   300  of    819.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    819.    Elapsed: 0:04:59.\n","DEBUG:__main__:  Batch   500  of    819.    Elapsed: 0:06:14.\n","DEBUG:__main__:  Batch   600  of    819.    Elapsed: 0:07:29.\n","DEBUG:__main__:  Batch   700  of    819.    Elapsed: 0:08:45.\n","DEBUG:__main__:  Batch   800  of    819.    Elapsed: 0:10:00.\n","INFO:__main__:Epoch 1 : \n","            Train_acc : 0.7965150235092895\n","            Train_precision (macro, micro): [0.60624501 0.79651502]\n","            Train_recall  (macro, micro): [0.52176935 0.79651502]\n","            Train_F1 : [0.51737883 0.79651502]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.45\n","INFO:__main__:  Training epoch took: 0:10:15\n","INFO:__main__:Classification report. TRAINING at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.95      0.98      0.97      2447\n","           1       0.84      0.96      0.90      2020\n","           2       0.79      0.94      0.86       736\n","           3       0.84      0.81      0.83       626\n","           4       0.30      0.08      0.12       323\n","           5       0.89      0.60      0.72       236\n","           6       1.00      0.17      0.29       162\n","\n","    accuracy                           0.87      6550\n","   macro avg       0.80      0.65      0.67      6550\n","weighted avg       0.86      0.87      0.85      6550\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 1 : \n","                Valid_acc : 0.9290969796474323\n","                Valid_precision (macro, micro): [0.91760889 0.92909698]\n","                Valid_recall (macro, micro): [0.78236385 0.92909698]\n","                Valid_F1 (macro, micro): [0.81475153 0.92909698]\n","INFO:__main__:  Accuracy: 0.93\n","INFO:__main__:  Validation Loss: 0.26\n","INFO:__main__:  Validation took: 0:00:25\n","INFO:__main__:Classification report. VALIDATION at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       272\n","           1       0.89      0.95      0.92       225\n","           2       0.89      1.00      0.94        82\n","           3       0.92      0.97      0.94        69\n","           4       0.61      0.31      0.41        36\n","           5       1.00      0.88      0.94        26\n","           6       1.00      0.39      0.56        18\n","\n","    accuracy                           0.93       728\n","   macro avg       0.90      0.79      0.81       728\n","weighted avg       0.92      0.93      0.92       728\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 2 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    819.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    819.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of    819.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    819.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of    819.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of    819.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of    819.    Elapsed: 0:08:44.\n","DEBUG:__main__:  Batch   800  of    819.    Elapsed: 0:09:59.\n","INFO:__main__:Epoch 2 : \n","            Train_acc : 0.9363765816882961\n","            Train_precision (macro, micro): [0.90515172 0.93637658]\n","            Train_recall  (macro, micro): [0.81919979 0.93637658]\n","            Train_F1 : [0.84398218 0.93637658]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.23\n","INFO:__main__:  Training epoch took: 0:10:14\n","INFO:__main__:Classification report. TRAINING at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99      2447\n","           1       0.91      0.95      0.93      2020\n","           2       0.94      0.97      0.95       736\n","           3       0.92      0.97      0.94       626\n","           4       0.73      0.52      0.61       323\n","           5       0.97      0.93      0.95       236\n","           6       0.90      0.49      0.64       162\n","\n","    accuracy                           0.94      6550\n","   macro avg       0.91      0.83      0.86      6550\n","weighted avg       0.94      0.94      0.94      6550\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 2 : \n","                Valid_acc : 0.9455300667027443\n","                Valid_precision (macro, micro): [0.89662    0.94553007]\n","                Valid_recall (macro, micro): [0.85841442 0.94553007]\n","                Valid_F1 (macro, micro): [0.87052919 0.94553007]\n","INFO:__main__:  Accuracy: 0.95\n","INFO:__main__:  Validation Loss: 0.19\n","INFO:__main__:  Validation took: 0:00:25\n","INFO:__main__:Classification report. VALIDATION at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       272\n","           1       0.92      0.93      0.93       225\n","           2       0.99      0.99      0.99        82\n","           3       0.93      1.00      0.97        69\n","           4       0.69      0.61      0.65        36\n","           5       1.00      0.96      0.98        26\n","           6       0.77      0.56      0.65        18\n","\n","    accuracy                           0.95       728\n","   macro avg       0.90      0.86      0.88       728\n","weighted avg       0.94      0.95      0.94       728\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 3 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of    819.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of    819.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of    819.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of    819.    Elapsed: 0:04:59.\n","DEBUG:__main__:  Batch   500  of    819.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of    819.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of    819.    Elapsed: 0:08:44.\n","DEBUG:__main__:  Batch   800  of    819.    Elapsed: 0:10:00.\n","INFO:__main__:Epoch 3 : \n","            Train_acc : 0.9700076922175158\n","            Train_precision (macro, micro): [0.95877394 0.97000769]\n","            Train_recall  (macro, micro): [0.91225623 0.97000769]\n","            Train_F1 : [0.93128065 0.97000769]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.12\n","INFO:__main__:  Training epoch took: 0:10:15\n","INFO:__main__:Classification report. TRAINING at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      2447\n","           1       0.96      0.97      0.96      2020\n","           2       0.97      0.99      0.98       736\n","           3       0.94      0.98      0.96       626\n","           4       0.88      0.81      0.85       323\n","           5       1.00      0.95      0.97       236\n","           6       0.93      0.77      0.84       162\n","\n","    accuracy                           0.97      6550\n","   macro avg       0.95      0.92      0.94      6550\n","weighted avg       0.97      0.97      0.97      6550\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 3 : \n","                Valid_acc : 0.9494032658794055\n","                Valid_precision (macro, micro): [0.92323465 0.94940327]\n","                Valid_recall (macro, micro): [0.85812722 0.94940327]\n","                Valid_F1 (macro, micro): [0.87786307 0.94940327]\n","INFO:__main__:  Accuracy: 0.95\n","INFO:__main__:  Validation Loss: 0.25\n","INFO:__main__:  Validation took: 0:00:25\n","INFO:__main__:Classification report. VALIDATION at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       272\n","           1       0.90      0.96      0.93       225\n","           2       0.96      0.99      0.98        82\n","           3       0.97      1.00      0.99        69\n","           4       0.83      0.42      0.56        36\n","           5       1.00      1.00      1.00        26\n","           6       0.71      0.56      0.63        18\n","\n","    accuracy                           0.95       728\n","   macro avg       0.91      0.85      0.87       728\n","weighted avg       0.94      0.95      0.94       728\n","\n","DEBUG:__main__:\n","INFO:__main__:Training complete!\n","INFO:__main__:Total training took 0:31:57 (h:mm:ss)\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:********************************************************************************\n","INFO:__main__:[{'epoch': 1, 'Training Loss': 0.44718275459708423, 'Training Accur.': 0.7965150235092895, 'Training Precision (macro)': 0.6062450142793518, 'Training Precision (micro)': 0.7965150235092895, 'Training Recall (macro)': 0.5217693539201322, 'Training Recall (micro)': 0.7965150235092895, 'Training F1 (macro)': 0.5173788326653822, 'Training F1 (micro)': 0.7965150235092895, 'Valid. Loss': 0.263053006062714, 'Valid. Accur.': 0.9271978021978022, 'Valid. Precision (macro)': 0.9176088911036591, 'Valid. Precision (micro)': 0.9290969796474323, 'Valid. Recall (macro)': 0.7823638526465961, 'Valid. Recall (micro)': 0.9290969796474323, 'Valid. F1 (macro)': 0.8147515307301555, 'Valid. F1 (micro)': 0.9290969796474323, 'Training Time': '0:10:15', 'Validation Time': '0:00:25'}, {'epoch': 2, 'Training Loss': 0.23386252128535606, 'Training Accur.': 0.9363765816882961, 'Training Precision (macro)': 0.9051517169401055, 'Training Precision (micro)': 0.9363765816882961, 'Training Recall (macro)': 0.819199787866392, 'Training Recall (micro)': 0.9363765816882961, 'Training F1 (macro)': 0.843982180742064, 'Training F1 (micro)': 0.9363765816882961, 'Valid. Loss': 0.19144455130867005, 'Valid. Accur.': 0.945054945054945, 'Valid. Precision (macro)': 0.8966200043599314, 'Valid. Precision (micro)': 0.9455300667027443, 'Valid. Recall (macro)': 0.858414421288408, 'Valid. Recall (micro)': 0.9455300667027443, 'Valid. F1 (macro)': 0.8705291852954217, 'Valid. F1 (micro)': 0.9455300667027443, 'Training Time': '0:10:14', 'Validation Time': '0:00:25'}, {'epoch': 3, 'Training Loss': 0.12414113029619277, 'Training Accur.': 0.9700076922175158, 'Training Precision (macro)': 0.9587739351814855, 'Training Precision (micro)': 0.9700076922175158, 'Training Recall (macro)': 0.9122562285214775, 'Training Recall (micro)': 0.9700076922175158, 'Training F1 (macro)': 0.9312806466194418, 'Training F1 (micro)': 0.9700076922175158, 'Valid. Loss': 0.25387997107687765, 'Valid. Accur.': 0.945054945054945, 'Valid. Precision (macro)': 0.923234648501772, 'Valid. Precision (micro)': 0.9494032658794055, 'Valid. Recall (macro)': 0.8581272201548519, 'Valid. Recall (micro)': 0.9494032658794055, 'Valid. F1 (macro)': 0.8778630717592018, 'Valid. F1 (micro)': 0.9494032658794055, 'Training Time': '0:10:15', 'Validation Time': '0:00:25'}]\n","DEBUG:__main__:********************************************************************************\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:Num of different roles in the dataset is 7 which are:\n","DEBUG:__main__:\t 1 - Witness\n","DEBUG:__main__:\t 2 - LawyerQA\n","DEBUG:__main__:\t 3 - JudgeProc\n","DEBUG:__main__:\t 4 - LawyerProc\n","DEBUG:__main__:\t 5 - JudgeQA\n","DEBUG:__main__:\t 6 - Court Proceedings\n","DEBUG:__main__:\t 7 - Accused\n","INFO:__main__:There are 1 GPU(s) available.\n","\n","These are the available devices:\n","INFO:__main__:\t 1 - Tesla T4\n","DEBUG:__main__:\n","\n","==> Selected device is 'cuda' <==\n","DEBUG:__main__:Loading BERT tokenizer...\n","INFO:__main__:Bert tokenizer was loaded successfully (bert-base-uncased)\n","\tdo_lower_case=True\n","INFO:__main__:Max sentence length: 323 found at index 2524. Sentence is:\n","\n","\n","As for -- I tried to raise three children from their mother, but I could not do that, but they were not from Amleang. As for the flood, I would like to tell you the truth as the following.  A flood from the mountainous area, I had explained to the Chambers earlier that that day there was a slight rain at the place about 9:00 a.m. in the morning.  It was not a heavy rain that day, but there was flood that's about one metre in height in one hour.  It's very quick.  I saw that.  Then I stand -- I stood next to the pits and I told them, \"Come out, come out\" including myself and others would catch the bin and water above my chest. Everybody was in the same situation. In the evening, about 3:00 p.m., then the water level went down. At that time, I rescued the prisoner and the guards to Chot's house.  It's the village chief of the Trapeang Traob village. And therefore there was no prisoner died in the flood there.  As I told Your Honours earlier, no one died in the flood.  No one climbed up into the tree.  And there was a small hill next to Chot's house.  Chot was the chief of the village and at that time we cross... we could not cross to the house of Brother Chot because there was a pond there.  And before the person did not see anything and come to testify at the court, we cannot say it is correct.\n","\n","\n","\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","INFO:__main__:\n","CORPUS TRAINING AND VALIDATION: \n","            \n","\t Length labels 9705\n","            \n","\t Length input_ids 9705\n","            \n","\t Length attention_masks 9705\n","            \n","\n","INFO:__main__:\n","\tCORPUS TRAINING:  \n","            \n","\t\t Length labels 8734\n","            \n","\t\t Length input_ids 8734\n","            \n","\t\t Length attention_masks 8734\n","INFO:__main__:\n","\tCORPUS VALIDATION: \n","            \n","\t\t Length labels 971\n","            \n","\t\t Length input_ids 971\n","            \n","\t\t Length attention_masks 971\n","INFO:__main__:\n","INFO:__main__:\n","CORPUS TEST: \n","            \n","\t Length labels 511\n","            \n","\t Length input_ids 511\n","            \n","\t Length attention_masks 511\n","            \n","\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 1 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,092.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of  1,092.    Elapsed: 0:02:30.\n","DEBUG:__main__:  Batch   300  of  1,092.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of  1,092.    Elapsed: 0:04:59.\n","DEBUG:__main__:  Batch   500  of  1,092.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of  1,092.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of  1,092.    Elapsed: 0:08:44.\n","DEBUG:__main__:  Batch   800  of  1,092.    Elapsed: 0:10:00.\n","DEBUG:__main__:  Batch   900  of  1,092.    Elapsed: 0:11:16.\n","DEBUG:__main__:  Batch 1,000  of  1,092.    Elapsed: 0:12:33.\n","INFO:__main__:Epoch 1 : \n","            Train_acc : 0.8062644770861854\n","            Train_precision (macro, micro): [0.63802044 0.80626448]\n","            Train_recall  (macro, micro): [0.54964805 0.80626448]\n","            Train_F1 : [0.54969368 0.80626448]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.43\n","INFO:__main__:  Training epoch took: 0:13:43\n","INFO:__main__:Classification report. TRAINING at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.96      0.98      0.97      3262\n","           1       0.85      0.96      0.90      2695\n","           2       0.80      0.93      0.86       982\n","           3       0.85      0.85      0.85       834\n","           4       0.38      0.10      0.16       431\n","           5       0.93      0.67      0.78       315\n","           6       0.75      0.19      0.30       215\n","\n","    accuracy                           0.88      8734\n","   macro avg       0.79      0.67      0.69      8734\n","weighted avg       0.86      0.88      0.86      8734\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 1 : \n","                Valid_acc : 0.9236049951982145\n","                Valid_precision (macro, micro): [0.81773824 0.923605  ]\n","                Valid_recall (macro, micro): [0.80040282 0.923605  ]\n","                Valid_F1 (macro, micro): [0.78032535 0.923605  ]\n","INFO:__main__:  Accuracy: 0.92\n","INFO:__main__:  Validation Loss: 0.23\n","INFO:__main__:  Validation took: 0:00:33\n","INFO:__main__:Classification report. VALIDATION at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       363\n","           1       0.90      0.90      0.90       299\n","           2       0.88      0.98      0.93       109\n","           3       0.96      1.00      0.98        93\n","           4       0.87      0.27      0.41        48\n","           5       0.97      0.94      0.96        35\n","           6       0.44      0.75      0.55        24\n","\n","    accuracy                           0.92       971\n","   macro avg       0.86      0.83      0.82       971\n","weighted avg       0.93      0.92      0.92       971\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 2 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,092.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of  1,092.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of  1,092.    Elapsed: 0:03:43.\n","DEBUG:__main__:  Batch   400  of  1,092.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of  1,092.    Elapsed: 0:06:12.\n","DEBUG:__main__:  Batch   600  of  1,092.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of  1,092.    Elapsed: 0:08:43.\n","DEBUG:__main__:  Batch   800  of  1,092.    Elapsed: 0:09:59.\n","DEBUG:__main__:  Batch   900  of  1,092.    Elapsed: 0:11:15.\n","DEBUG:__main__:  Batch 1,000  of  1,092.    Elapsed: 0:12:32.\n","INFO:__main__:Epoch 2 : \n","            Train_acc : 0.9419572730077427\n","            Train_precision (macro, micro): [0.89754195 0.94195727]\n","            Train_recall  (macro, micro): [0.84378732 0.94195727]\n","            Train_F1 : [0.86081501 0.94195727]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.21\n","INFO:__main__:  Training epoch took: 0:13:43\n","INFO:__main__:Classification report. TRAINING at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00      3262\n","           1       0.91      0.95      0.93      2695\n","           2       0.94      0.98      0.96       982\n","           3       0.94      0.97      0.96       834\n","           4       0.76      0.46      0.57       431\n","           5       0.97      0.95      0.96       315\n","           6       0.78      0.62      0.69       215\n","\n","    accuracy                           0.94      8734\n","   macro avg       0.90      0.85      0.87      8734\n","weighted avg       0.94      0.94      0.94      8734\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 2 : \n","                Valid_acc : 0.9458195123083307\n","                Valid_precision (macro, micro): [0.92418027 0.94581951]\n","                Valid_recall (macro, micro): [0.85647082 0.94581951]\n","                Valid_F1 (macro, micro): [0.88143795 0.94581951]\n","INFO:__main__:  Accuracy: 0.95\n","INFO:__main__:  Validation Loss: 0.20\n","INFO:__main__:  Validation took: 0:00:33\n","INFO:__main__:Classification report. VALIDATION at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       363\n","           1       0.92      0.96      0.94       299\n","           2       0.92      0.93      0.92       109\n","           3       0.96      0.96      0.96        93\n","           4       0.85      0.58      0.69        48\n","           5       0.97      0.97      0.97        35\n","           6       0.75      0.62      0.68        24\n","\n","    accuracy                           0.95       971\n","   macro avg       0.91      0.86      0.88       971\n","weighted avg       0.94      0.95      0.94       971\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 3 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,092.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of  1,092.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of  1,092.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of  1,092.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of  1,092.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of  1,092.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of  1,092.    Elapsed: 0:08:43.\n","DEBUG:__main__:  Batch   800  of  1,092.    Elapsed: 0:09:59.\n","DEBUG:__main__:  Batch   900  of  1,092.    Elapsed: 0:11:15.\n","DEBUG:__main__:  Batch 1,000  of  1,092.    Elapsed: 0:12:32.\n","INFO:__main__:Epoch 3 : \n","            Train_acc : 0.9614585823997986\n","            Train_precision (macro, micro): [0.9438434  0.96145858]\n","            Train_recall  (macro, micro): [0.8998926  0.96145858]\n","            Train_F1 : [0.91782048 0.96145858]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.14\n","INFO:__main__:  Training epoch took: 0:13:42\n","INFO:__main__:Classification report. TRAINING at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      3262\n","           1       0.95      0.98      0.96      2695\n","           2       0.95      0.97      0.96       982\n","           3       0.96      0.98      0.97       834\n","           4       0.84      0.70      0.77       431\n","           5       0.98      0.97      0.97       315\n","           6       0.92      0.80      0.85       215\n","\n","    accuracy                           0.97      8734\n","   macro avg       0.94      0.91      0.93      8734\n","weighted avg       0.96      0.97      0.96      8734\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 3 : \n","                Valid_acc : 0.9569436928002619\n","                Valid_precision (macro, micro): [0.92198305 0.95694369]\n","                Valid_recall (macro, micro): [0.92853711 0.95694369]\n","                Valid_F1 (macro, micro): [0.92065821 0.95694369]\n","INFO:__main__:  Accuracy: 0.95\n","INFO:__main__:  Validation Loss: 0.18\n","INFO:__main__:  Validation took: 0:00:33\n","INFO:__main__:Classification report. VALIDATION at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       363\n","           1       0.95      0.94      0.94       299\n","           2       0.94      0.94      0.94       109\n","           3       0.93      1.00      0.96        93\n","           4       0.79      0.62      0.70        48\n","           5       1.00      1.00      1.00        35\n","           6       0.75      0.88      0.81        24\n","\n","    accuracy                           0.95       971\n","   macro avg       0.91      0.91      0.91       971\n","weighted avg       0.95      0.95      0.95       971\n","\n","DEBUG:__main__:\n","INFO:__main__:Training complete!\n","INFO:__main__:Total training took 0:42:47 (h:mm:ss)\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:********************************************************************************\n","INFO:__main__:[{'epoch': 1, 'Training Loss': 0.4292692149317254, 'Training Accur.': 0.8062644770861854, 'Training Precision (macro)': 0.6380204392899647, 'Training Precision (micro)': 0.8062644770861854, 'Training Recall (macro)': 0.5496480545637542, 'Training Recall (micro)': 0.8062644770861854, 'Training F1 (macro)': 0.5496936818774638, 'Training F1 (micro)': 0.8062644770861854, 'Valid. Loss': 0.2336193000531343, 'Valid. Accur.': 0.9211065573770492, 'Valid. Precision (macro)': 0.8177382416172905, 'Valid. Precision (micro)': 0.9236049951982145, 'Valid. Recall (macro)': 0.800402819885766, 'Valid. Recall (micro)': 0.9236049951982145, 'Valid. F1 (macro)': 0.7803253533991817, 'Valid. F1 (micro)': 0.9236049951982145, 'Training Time': '0:13:43', 'Validation Time': '0:00:33'}, {'epoch': 2, 'Training Loss': 0.21480739059185971, 'Training Accur.': 0.9419572730077427, 'Training Precision (macro)': 0.897541947760697, 'Training Precision (micro)': 0.9419572730077427, 'Training Recall (macro)': 0.8437873194063173, 'Training Recall (micro)': 0.9419572730077427, 'Training F1 (macro)': 0.8608150102843005, 'Training F1 (micro)': 0.9419572730077427, 'Valid. Loss': 0.1975588304616633, 'Valid. Accur.': 0.9456967213114754, 'Valid. Precision (macro)': 0.9241802734862166, 'Valid. Precision (micro)': 0.9458195123083307, 'Valid. Recall (macro)': 0.8564708201117797, 'Valid. Recall (micro)': 0.9458195123083307, 'Valid. F1 (macro)': 0.8814379502246114, 'Valid. F1 (micro)': 0.9458195123083307, 'Training Time': '0:13:43', 'Validation Time': '0:00:33'}, {'epoch': 3, 'Training Loss': 0.13831999245188847, 'Training Accur.': 0.9614585823997986, 'Training Precision (macro)': 0.9438433990271274, 'Training Precision (micro)': 0.9614585823997986, 'Training Recall (macro)': 0.8998926029405547, 'Training Recall (micro)': 0.9614585823997986, 'Training F1 (macro)': 0.9178204773502074, 'Training F1 (micro)': 0.9614585823997986, 'Valid. Loss': 0.18438732746862577, 'Valid. Accur.': 0.9528688524590164, 'Valid. Precision (macro)': 0.9219830458585176, 'Valid. Precision (micro)': 0.9569436928002619, 'Valid. Recall (macro)': 0.9285371064078578, 'Valid. Recall (micro)': 0.9569436928002619, 'Valid. F1 (macro)': 0.9206582144828067, 'Valid. F1 (micro)': 0.9569436928002619, 'Training Time': '0:13:42', 'Validation Time': '0:00:33'}]\n","DEBUG:__main__:********************************************************************************\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:Num of different roles in the dataset is 7 which are:\n","DEBUG:__main__:\t 1 - Witness\n","DEBUG:__main__:\t 2 - LawyerQA\n","DEBUG:__main__:\t 3 - JudgeProc\n","DEBUG:__main__:\t 4 - LawyerProc\n","DEBUG:__main__:\t 5 - JudgeQA\n","DEBUG:__main__:\t 6 - Court Proceedings\n","DEBUG:__main__:\t 7 - Accused\n","INFO:__main__:There are 1 GPU(s) available.\n","\n","These are the available devices:\n","INFO:__main__:\t 1 - Tesla T4\n","DEBUG:__main__:\n","\n","==> Selected device is 'cuda' <==\n","DEBUG:__main__:Loading BERT tokenizer...\n","INFO:__main__:Bert tokenizer was loaded successfully (bert-base-uncased)\n","\tdo_lower_case=True\n","INFO:__main__:Max sentence length: 342 found at index 11778. Sentence is:\n","\n","\n","Q. I'm going to quote what you said. Well, in fact, you mentioned his name at -- in the written record, D40/23, in Khmer 00165357; in French 00490912; English 00223212. Question: \"Among the prisoners who were brought to the centre, were some released?\" Your answer: \"Only the female prisoners with their children were released, in particular, the family of Yeay Nhor,\" N-H-O-R, \"And most of the prisoners died because they were ill or because they were executed. Very few prisoners survived. That is to say, Sen, who was one of them, who lives next to Angkor Leay pagoda.\" End of quote. And here you spoke about Yeay Nha's family, at answers 90 to 92, at E319.1.3. So those are answers 90 to 92, you spoke about certain members of Yeay Nhor's family, or Yeay Nha, who were detained but who survived Krang Ta Chan. And you also said in your written record of interview, which I just quoted from, that prisoners died because they had been beaten during the interrogations and you also spoke about Yeay Nha's husband as well as the spouse of a -- spouse of a surname Rat (phonetic) was one of Yeay Nha's daughters. Can you tell us when you arrived at Krang Ta Chan, were the members of this family, the family of Yeay Nha, were they already on site, or did they arrive after you had been assigned to Krang Ta Chan?\n","\n","\n","\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","INFO:__main__:\n","CORPUS TRAINING AND VALIDATION: \n","            \n","\t Length labels 12137\n","            \n","\t Length input_ids 12137\n","            \n","\t Length attention_masks 12137\n","            \n","\n","INFO:__main__:\n","\tCORPUS TRAINING:  \n","            \n","\t\t Length labels 10923\n","            \n","\t\t Length input_ids 10923\n","            \n","\t\t Length attention_masks 10923\n","INFO:__main__:\n","\tCORPUS VALIDATION: \n","            \n","\t\t Length labels 1214\n","            \n","\t\t Length input_ids 1214\n","            \n","\t\t Length attention_masks 1214\n","INFO:__main__:\n","INFO:__main__:\n","CORPUS TEST: \n","            \n","\t Length labels 639\n","            \n","\t Length input_ids 639\n","            \n","\t Length attention_masks 639\n","            \n","\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 1 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,366.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of  1,366.    Elapsed: 0:02:30.\n","DEBUG:__main__:  Batch   300  of  1,366.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of  1,366.    Elapsed: 0:04:59.\n","DEBUG:__main__:  Batch   500  of  1,366.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of  1,366.    Elapsed: 0:07:29.\n","DEBUG:__main__:  Batch   700  of  1,366.    Elapsed: 0:08:44.\n","DEBUG:__main__:  Batch   800  of  1,366.    Elapsed: 0:10:00.\n","DEBUG:__main__:  Batch   900  of  1,366.    Elapsed: 0:11:16.\n","DEBUG:__main__:  Batch 1,000  of  1,366.    Elapsed: 0:12:32.\n","DEBUG:__main__:  Batch 1,100  of  1,366.    Elapsed: 0:13:49.\n","DEBUG:__main__:  Batch 1,200  of  1,366.    Elapsed: 0:15:06.\n","DEBUG:__main__:  Batch 1,300  of  1,366.    Elapsed: 0:16:24.\n","INFO:__main__:Epoch 1 : \n","            Train_acc : 0.8239347351244178\n","            Train_precision (macro, micro): [0.68382153 0.82393474]\n","            Train_recall  (macro, micro): [0.57456014 0.82393474]\n","            Train_F1 : [0.57665691 0.82393474]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.40\n","INFO:__main__:  Training epoch took: 0:17:15\n","INFO:__main__:Classification report. TRAINING at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.97      4078\n","           1       0.86      0.96      0.90      3370\n","           2       0.81      0.95      0.87      1229\n","           3       0.86      0.86      0.86      1043\n","           4       0.42      0.07      0.13       539\n","           5       0.92      0.71      0.80       394\n","           6       0.74      0.28      0.40       270\n","\n","    accuracy                           0.89     10923\n","   macro avg       0.79      0.69      0.71     10923\n","weighted avg       0.87      0.89      0.87     10923\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 1 : \n","                Valid_acc : 0.9311728725119565\n","                Valid_precision (macro, micro): [0.88748459 0.93117287]\n","                Valid_recall (macro, micro): [0.79461786 0.93117287]\n","                Valid_F1 (macro, micro): [0.81626649 0.93117287]\n","INFO:__main__:  Accuracy: 0.93\n","INFO:__main__:  Validation Loss: 0.23\n","INFO:__main__:  Validation took: 0:00:41\n","INFO:__main__:Classification report. VALIDATION at epoch 1 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       453\n","           1       0.89      0.98      0.93       375\n","           2       0.91      0.97      0.94       136\n","           3       0.95      0.96      0.95       116\n","           4       0.89      0.28      0.43        60\n","           5       0.98      0.95      0.97        44\n","           6       0.67      0.53      0.59        30\n","\n","    accuracy                           0.93      1214\n","   macro avg       0.90      0.81      0.83      1214\n","weighted avg       0.93      0.93      0.93      1214\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 2 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,366.    Elapsed: 0:01:14.\n","DEBUG:__main__:  Batch   200  of  1,366.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of  1,366.    Elapsed: 0:03:43.\n","DEBUG:__main__:  Batch   400  of  1,366.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of  1,366.    Elapsed: 0:06:12.\n","DEBUG:__main__:  Batch   600  of  1,366.    Elapsed: 0:07:27.\n","DEBUG:__main__:  Batch   700  of  1,366.    Elapsed: 0:08:43.\n","DEBUG:__main__:  Batch   800  of  1,366.    Elapsed: 0:09:59.\n","DEBUG:__main__:  Batch   900  of  1,366.    Elapsed: 0:11:15.\n","DEBUG:__main__:  Batch 1,000  of  1,366.    Elapsed: 0:12:32.\n","DEBUG:__main__:  Batch 1,100  of  1,366.    Elapsed: 0:13:49.\n","DEBUG:__main__:  Batch 1,200  of  1,366.    Elapsed: 0:15:06.\n","DEBUG:__main__:  Batch 1,300  of  1,366.    Elapsed: 0:16:24.\n","INFO:__main__:Epoch 2 : \n","            Train_acc : 0.9447177657617155\n","            Train_precision (macro, micro): [0.89990532 0.94471777]\n","            Train_recall  (macro, micro): [0.85275824 0.94471777]\n","            Train_F1 : [0.86944892 0.94471777]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.20\n","INFO:__main__:  Training epoch took: 0:17:15\n","INFO:__main__:Classification report. TRAINING at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00      4078\n","           1       0.92      0.96      0.94      3370\n","           2       0.94      0.97      0.95      1229\n","           3       0.94      0.97      0.96      1043\n","           4       0.79      0.54      0.64       539\n","           5       0.98      0.94      0.96       394\n","           6       0.83      0.62      0.71       270\n","\n","    accuracy                           0.95     10923\n","   macro avg       0.91      0.86      0.88     10923\n","weighted avg       0.94      0.95      0.94     10923\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 2 : \n","                Valid_acc : 0.9489700028380335\n","                Valid_precision (macro, micro): [0.90769797 0.94897   ]\n","                Valid_recall (macro, micro): [0.85511617 0.94897   ]\n","                Valid_F1 (macro, micro): [0.86467309 0.94897   ]\n","INFO:__main__:  Accuracy: 0.94\n","INFO:__main__:  Validation Loss: 0.24\n","INFO:__main__:  Validation took: 0:00:41\n","INFO:__main__:Classification report. VALIDATION at epoch 2 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       453\n","           1       0.91      0.97      0.94       375\n","           2       0.93      0.97      0.95       136\n","           3       0.93      0.98      0.96       116\n","           4       0.86      0.40      0.55        60\n","           5       0.98      0.98      0.98        44\n","           6       0.73      0.63      0.68        30\n","\n","    accuracy                           0.94      1214\n","   macro avg       0.90      0.85      0.86      1214\n","weighted avg       0.94      0.94      0.94      1214\n","\n","DEBUG:__main__:\n","DEBUG:__main__:======== Epoch 3 / 3 ========\n","DEBUG:__main__:Training...\n","DEBUG:__main__:  Batch   100  of  1,366.    Elapsed: 0:01:15.\n","DEBUG:__main__:  Batch   200  of  1,366.    Elapsed: 0:02:29.\n","DEBUG:__main__:  Batch   300  of  1,366.    Elapsed: 0:03:44.\n","DEBUG:__main__:  Batch   400  of  1,366.    Elapsed: 0:04:58.\n","DEBUG:__main__:  Batch   500  of  1,366.    Elapsed: 0:06:13.\n","DEBUG:__main__:  Batch   600  of  1,366.    Elapsed: 0:07:28.\n","DEBUG:__main__:  Batch   700  of  1,366.    Elapsed: 0:08:44.\n","DEBUG:__main__:  Batch   800  of  1,366.    Elapsed: 0:09:59.\n","DEBUG:__main__:  Batch   900  of  1,366.    Elapsed: 0:11:16.\n","DEBUG:__main__:  Batch 1,000  of  1,366.    Elapsed: 0:12:32.\n","DEBUG:__main__:  Batch 1,100  of  1,366.    Elapsed: 0:13:49.\n","DEBUG:__main__:  Batch 1,200  of  1,366.    Elapsed: 0:15:06.\n","DEBUG:__main__:  Batch 1,300  of  1,366.    Elapsed: 0:16:24.\n","INFO:__main__:Epoch 3 : \n","            Train_acc : 0.9673970367433907\n","            Train_precision (macro, micro): [0.94938032 0.96739704]\n","            Train_recall  (macro, micro): [0.92564538 0.96739704]\n","            Train_F1 : [0.93501437 0.96739704]\n","DEBUG:__main__:\n","INFO:__main__:  Average training loss: 0.13\n","INFO:__main__:  Training epoch took: 0:17:15\n","INFO:__main__:Classification report. TRAINING at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      4078\n","           1       0.96      0.97      0.97      3370\n","           2       0.96      0.98      0.97      1229\n","           3       0.95      0.97      0.96      1043\n","           4       0.88      0.77      0.82       539\n","           5       0.98      0.97      0.97       394\n","           6       0.93      0.85      0.89       270\n","\n","    accuracy                           0.97     10923\n","   macro avg       0.95      0.93      0.94     10923\n","weighted avg       0.97      0.97      0.97     10923\n","\n","DEBUG:__main__:\n","INFO:__main__:Running Validation...\n","INFO:__main__:Epoch 3 : \n","                Valid_acc : 0.9559274640913946\n","                Valid_precision (macro, micro): [0.93771294 0.95592746]\n","                Valid_recall (macro, micro): [0.85405103 0.95592746]\n","                Valid_F1 (macro, micro): [0.87875598 0.95592746]\n","INFO:__main__:  Accuracy: 0.96\n","INFO:__main__:  Validation Loss: 0.22\n","INFO:__main__:  Validation took: 0:00:41\n","INFO:__main__:Classification report. VALIDATION at epoch 3 \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       453\n","           1       0.93      0.98      0.96       375\n","           2       0.92      0.98      0.95       136\n","           3       0.94      0.98      0.96       116\n","           4       0.89      0.57      0.69        60\n","           5       1.00      0.95      0.98        44\n","           6       0.94      0.57      0.71        30\n","\n","    accuracy                           0.96      1214\n","   macro avg       0.95      0.86      0.89      1214\n","weighted avg       0.96      0.96      0.95      1214\n","\n","DEBUG:__main__:\n","INFO:__main__:Training complete!\n","INFO:__main__:Total training took 0:53:48 (h:mm:ss)\n","DEBUG:__main__:====================================================================================================\n","DEBUG:__main__:********************************************************************************\n","INFO:__main__:[{'epoch': 1, 'Training Loss': 0.3996505447701547, 'Training Accur.': 0.8239347351244178, 'Training Precision (macro)': 0.683821525652662, 'Training Precision (micro)': 0.8239347351244178, 'Training Recall (macro)': 0.5745601426823458, 'Training Recall (micro)': 0.8239347351244178, 'Training F1 (macro)': 0.5766569149467256, 'Training F1 (micro)': 0.8239347351244178, 'Valid. Loss': 0.23345147260452473, 'Valid. Accur.': 0.9347587719298246, 'Valid. Precision (macro)': 0.887484591847227, 'Valid. Precision (micro)': 0.9311728725119565, 'Valid. Recall (macro)': 0.7946178563863263, 'Valid. Recall (micro)': 0.9311728725119565, 'Valid. F1 (macro)': 0.8162664878640236, 'Valid. F1 (micro)': 0.9311728725119565, 'Training Time': '0:17:15', 'Validation Time': '0:00:41'}, {'epoch': 2, 'Training Loss': 0.20379231723138277, 'Training Accur.': 0.9447177657617155, 'Training Precision (macro)': 0.8999053151506428, 'Training Precision (micro)': 0.9447177657617155, 'Training Recall (macro)': 0.8527582375281435, 'Training Recall (micro)': 0.9447177657617155, 'Training F1 (macro)': 0.8694489220259981, 'Training F1 (micro)': 0.9447177657617155, 'Valid. Loss': 0.23929256887793982, 'Valid. Accur.': 0.9432565789473685, 'Valid. Precision (macro)': 0.9076979714987007, 'Valid. Precision (micro)': 0.9489700028380335, 'Valid. Recall (macro)': 0.8551161724640364, 'Valid. Recall (micro)': 0.9489700028380335, 'Valid. F1 (macro)': 0.8646730885990294, 'Valid. F1 (micro)': 0.9489700028380335, 'Training Time': '0:17:15', 'Validation Time': '0:00:41'}, {'epoch': 3, 'Training Loss': 0.1300524215867704, 'Training Accur.': 0.9673970367433907, 'Training Precision (macro)': 0.9493803201172045, 'Training Precision (micro)': 0.9673970367433907, 'Training Recall (macro)': 0.9256453843986068, 'Training Recall (micro)': 0.9673970367433907, 'Training F1 (macro)': 0.935014371548432, 'Training F1 (micro)': 0.9673970367433907, 'Valid. Loss': 0.21885956326973668, 'Valid. Accur.': 0.9555921052631579, 'Valid. Precision (macro)': 0.937712940164691, 'Valid. Precision (micro)': 0.9559274640913946, 'Valid. Recall (macro)': 0.8540510305938664, 'Valid. Recall (micro)': 0.9559274640913946, 'Valid. F1 (macro)': 0.8787559822671416, 'Valid. F1 (micro)': 0.9559274640913946, 'Training Time': '0:17:15', 'Validation Time': '0:00:41'}]\n","DEBUG:__main__:********************************************************************************\n","DEBUG:__main__:====================================================================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kHsgV5_dTpex"},"execution_count":null,"outputs":[]}]}