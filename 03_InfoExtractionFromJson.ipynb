{"cells":[{"cell_type":"code","execution_count":null,"id":"52e12cfa","metadata":{"id":"52e12cfa"},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","from os.path import join"]},{"cell_type":"code","source":["\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Colab Notebooks\"\n","username = \"IsaacOlguin\"\n","repository =  \"AutomatedTraumaDetectionInGCT\"\n","%cd {repository}\n","%pwd\n","%ls\n","\"\"\""],"metadata":{"id":"J-VjW8dlgBqA"},"id":"J-VjW8dlgBqA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"8deaee9d","metadata":{"id":"8deaee9d"},"outputs":[],"source":["dataset_json_path = \"input/json/20221203_task_export.json\"\n","dataset_excel_path = \"input/dataset/Dataset.xlsx\""]},{"cell_type":"code","execution_count":null,"id":"353f06a6","metadata":{"id":"353f06a6"},"outputs":[],"source":["dataset_json = json.load(open(dataset_json_path))\n","\"\"\"\n","#=====================================================================================\n","print(dataset_json.keys())\n","\n","#=====================================================================================\n","#dataset_json[\"documents\"] #ArrayList\n","print(\"=\"*50)\n","print(f\"Number of documents in the source dataset {len(dataset_json['documents'])}\")\n","\n","if len(dataset_json['documents']) > 0:\n","    print(f\"Keys of the document at index [0] are {((dataset_json['documents'])[0]).keys()}\")\n","    \n","    \n","print(\"=\"*50)\n","print(f\"Number of types in the source dataset {len(dataset_json['types'])}\")\n","\n","if len(dataset_json['types']) > 0:\n","    print(f\"Keys of the type at index [0] are {((dataset_json['types'])[0]).keys()}\")\n","    \n","    \n","print(\"=\"*50)\n","print(f\"Number of annotations in the source dataset {len(dataset_json['annotations'])}\")\n","\n","if len(dataset_json['annotations']) > 0:\n","    print(f\"Keys of the annotation at index [0] are {((dataset_json['annotations'])[0]).keys()}\")\n","    \n","print(\"=\"*50)\n","print(f\"Number of objects in the source dataset {len(dataset_json['objects'])}\")\n","\n","if len(dataset_json['objects']) > 0:\n","    print(f\"Keys of the object at index [0] are {((dataset_json['objects'])[0]).keys()}\")\n","\n","#=====================================================================================\n","for doc in dataset_json['documents']:\n","    print(f\"Name: {doc['name']}\\nId: {doc['_id']}\\n\")# also contains plainText\n","\n","#=====================================================================================\n","for _type in dataset_json['types'][0:1]:\n","    print(f\"Name: {_type['name']}\\nisA: {_type['isA']}\\nid: {_type['_id']}\\nAttributes: {_type['attributes']}\\n\")\n","\n","#=====================================================================================\n","for annotation in dataset_json['annotations'][0:1]:\n","    print(f\"_id: {annotation['_id']}\\nDocument: {annotation['document']}\", end=\"\")\n","    print(f\"\\nStart & End: [{annotation['start']}:{annotation['end']}]\", end=\"\")\n","    print(f\"\\nType: {annotation['type']}\")\n","    #print(f\"\\nAttributes: {annotation['attributes']}\")\n","\"\"\"\n","#=====================================================================================\n","dict_documents = {}\n","for doc in dataset_json['documents']:\n","    dict_documents[doc['_id']] = {}\n","    dict_documents[doc['_id']][\"name\"] = doc['name']\n","    dict_documents[doc['_id']][\"court\"] = doc['name'][0:doc['name'].find(\"_\")]\n","    dict_documents[doc['_id']][\"plainText\"] = doc['plainText']\n","    \n","dict_types = {}\n","for _type in dataset_json['types']:\n","    dict_types[_type['_id']] = {}\n","    dict_types[_type['_id']][\"name\"] = _type['name']\n","    \n","#print(dict_documents)\n","\n","#=====================================================================================\n","list_annotations = list()\n","for annotation in dataset_json['annotations']:\n","    new_register = list()\n","    \n","    # Text - plainText\n","    new_register.append(dict_documents[annotation['document']][\"plainText\"][annotation['start']:annotation['end']])\n","    # Role\n","    new_register.append(dict_types[annotation['type']][\"name\"])\n","    # Trauma - default value = 0\n","    new_register.append(0)\n","    # Court\n","    new_register.append(dict_documents[annotation['document']][\"court\"])\n","    # Date\n","    # etc.\n","    \n","    ### Save new register to list of annotations\n","    list_annotations.append(new_register)\n","\n","df = pd.DataFrame(list_annotations, columns=[\"text\", \"role\", \"trauma\", \"court\"])\n","df.to_excel(dataset_excel_path, index=False)\n","\n","#=====================================================================================\n","print(\"\\n\\n\\t\\tExtraction of information was successfully executed!!!\")"]},{"cell_type":"code","execution_count":null,"id":"0c01da8c","metadata":{"id":"0c01da8c"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}